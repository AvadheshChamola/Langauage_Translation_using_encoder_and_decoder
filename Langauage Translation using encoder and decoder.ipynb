{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Langauage Translation using encoder and decoder.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMs08RN0g3vTyOT30kjC/Ib"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QiXoBUKTYEL0","executionInfo":{"status":"ok","timestamp":1627925400721,"user_tz":-330,"elapsed":426,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}},"outputId":"cba53cea-e765-4cb2-9cbe-8d621a574a9d"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"auPbrdGpYTUl","executionInfo":{"status":"ok","timestamp":1627925402105,"user_tz":-330,"elapsed":4,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["datapath=\"/content/drive/MyDrive/Colab Notebooks/NLP/fra-eng/fra.txt\"\n","datapathhe=\"/content/drive/MyDrive/Colab Notebooks/NLP/hin-eng/hin.txt\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_uTbup6Yvi3","executionInfo":{"status":"ok","timestamp":1627925405666,"user_tz":-330,"elapsed":1729,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input,LSTM,Dense\n","import numpy as np\n","epochs=100\n","batch_size=64\n","latent_dim=256\n","num_samples=100000"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"-QBPg9z6cKl8","executionInfo":{"status":"ok","timestamp":1627925408915,"user_tz":-330,"elapsed":1498,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["input_texts=[]\n","target_texts=[]\n","input_character=set()\n","target_character=set()\n","with open(datapath, 'r',encoding='utf-8') as f:\n","  lines=f.read().split('\\n');\n","for line in lines[:min(num_samples,len(lines)-1)]:\n","  input_text,target_text,_=line.split('\\t')\n","  target_text='\\t'+target_text+'\\n'\n","  input_texts.append(input_text)\n","  target_texts.append(target_text)\n","  for char in input_text:\n","    if char not in input_character:\n","      input_character.add(char)\n","  for char in target_text:\n","    if char not in target_character:\n","      target_character.add(char)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y-w-xBKrd2wE","executionInfo":{"status":"ok","timestamp":1627925410494,"user_tz":-330,"elapsed":5,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["input_character=sorted(list(input_character))\n","target_character=sorted(list(target_character))\n","num_encoder_tokens=len(input_character)\n","num_decoder_tokens=len(target_character)\n","max_encoder_seq_length=max([len(txt) for txt in input_texts])\n","max_decoder_seq_length=max([len(txt) for txt in target_texts])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdXz7Gr9hrpX","executionInfo":{"status":"ok","timestamp":1627925412292,"user_tz":-330,"elapsed":11,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}},"outputId":"27886089-1b2e-4ee6-e7ec-ccb410345668"},"source":["print(\"input_character: \",input_character)\n","print(\"target_character:\",target_character)\n","print(\"num_encoder_token:\",num_encoder_tokens)\n","print(\"num_decoder_token:\",num_decoder_tokens)\n","print(\"max_encoder_seq_length:\",max_encoder_seq_length)\n","print(\"max_decoder_seq_length:\",max_decoder_seq_length)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["input_character:  [' ', '!', '\"', '$', '%', '&', \"'\", ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é', '’', '€']\n","target_character: ['\\t', '\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '«', '»', 'À', 'Ç', 'É', 'Ê', 'Ô', 'à', 'â', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û', 'œ', 'С', '\\u2009', '\\u200b', '‘', '’', '\\u202f']\n","num_encoder_token: 78\n","num_decoder_token: 106\n","max_encoder_seq_length: 29\n","max_decoder_seq_length: 78\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3JXBDaTeotD6","executionInfo":{"status":"ok","timestamp":1627925414367,"user_tz":-330,"elapsed":4,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["input_token_index=dict([(char,i) for i,char in enumerate(input_character)])\n","target_token_index=dict([(char,i) for i,char in enumerate(target_character)])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"66tsyOIlpMEl","executionInfo":{"status":"ok","timestamp":1627925418349,"user_tz":-330,"elapsed":2280,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["encoder_input_data=np.zeros((len(input_texts),max_encoder_seq_length,num_encoder_tokens),dtype=\"float32\")\n","decoder_input_data=np.zeros((len(input_texts),max_decoder_seq_length,num_decoder_tokens),dtype=\"float32\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYvcO7Kj6Bzl","executionInfo":{"status":"ok","timestamp":1627925422478,"user_tz":-330,"elapsed":1850,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["decoder_target_data=np.zeros((len(input_texts),max_decoder_seq_length,num_decoder_tokens),dtype=\"float32\")"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"eGp-ODLPCr0J","executionInfo":{"status":"ok","timestamp":1627925427930,"user_tz":-330,"elapsed":3761,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n","  for t,char in enumerate(input_text):\n","    encoder_input_data[i,t,input_token_index[char]]=1\n","  encoder_input_data[i,t+1:,input_token_index[' ']]=1\n","\n","  for t,char in enumerate(target_text):\n","    decoder_input_data[i,t,target_token_index[char]]=1\n","    if t>0:\n","      decoder_target_data[i,t-1,target_token_index[char]]=1\n","  decoder_input_data[i,t+1:,target_token_index[' ']]=1\n","  decoder_target_data[i,t:,target_token_index[' ']]=1"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsSVZpVmCuDy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627925439187,"user_tz":-330,"elapsed":424,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}},"outputId":"6098fcac-09d7-4848-db6d-06145f5df325"},"source":["encoder_input_data[0].shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(29, 78)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"36DR9HskPBUp","executionInfo":{"status":"ok","timestamp":1627925448411,"user_tz":-330,"elapsed":7271,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the \n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"eauHfuAxPtDD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627927456346,"user_tz":-330,"elapsed":2004593,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}},"outputId":"025f7c06-a8bb-4ee3-b2c9-db2d3cde6734"},"source":["model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.2)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1250/1250 [==============================] - 28s 16ms/step - loss: 0.7097 - accuracy: 0.8006 - val_loss: 0.7024 - val_accuracy: 0.7900\n","Epoch 2/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.4535 - accuracy: 0.8640 - val_loss: 0.5545 - val_accuracy: 0.8336\n","Epoch 3/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.3783 - accuracy: 0.8859 - val_loss: 0.4885 - val_accuracy: 0.8526\n","Epoch 4/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.3364 - accuracy: 0.8981 - val_loss: 0.4549 - val_accuracy: 0.8626\n","Epoch 5/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.3104 - accuracy: 0.9055 - val_loss: 0.4318 - val_accuracy: 0.8692\n","Epoch 6/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.2921 - accuracy: 0.9108 - val_loss: 0.4169 - val_accuracy: 0.8734\n","Epoch 7/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.2785 - accuracy: 0.9147 - val_loss: 0.4051 - val_accuracy: 0.8772\n","Epoch 8/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.2677 - accuracy: 0.9176 - val_loss: 0.3985 - val_accuracy: 0.8791\n","Epoch 9/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.2587 - accuracy: 0.9202 - val_loss: 0.3926 - val_accuracy: 0.8810\n","Epoch 10/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.2509 - accuracy: 0.9225 - val_loss: 0.3878 - val_accuracy: 0.8825\n","Epoch 11/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.2440 - accuracy: 0.9245 - val_loss: 0.3845 - val_accuracy: 0.8835\n","Epoch 12/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.2380 - accuracy: 0.9262 - val_loss: 0.3808 - val_accuracy: 0.8848\n","Epoch 13/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.2326 - accuracy: 0.9278 - val_loss: 0.3780 - val_accuracy: 0.8862\n","Epoch 14/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.2276 - accuracy: 0.9293 - val_loss: 0.3771 - val_accuracy: 0.8867\n","Epoch 15/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.2232 - accuracy: 0.9305 - val_loss: 0.3771 - val_accuracy: 0.8867\n","Epoch 16/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.2191 - accuracy: 0.9317 - val_loss: 0.3754 - val_accuracy: 0.8876\n","Epoch 17/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.2153 - accuracy: 0.9329 - val_loss: 0.3771 - val_accuracy: 0.8876\n","Epoch 18/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.2120 - accuracy: 0.9339 - val_loss: 0.3751 - val_accuracy: 0.8880\n","Epoch 19/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.2085 - accuracy: 0.9349 - val_loss: 0.3759 - val_accuracy: 0.8881\n","Epoch 20/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.2054 - accuracy: 0.9358 - val_loss: 0.3760 - val_accuracy: 0.8886\n","Epoch 21/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.2026 - accuracy: 0.9366 - val_loss: 0.3772 - val_accuracy: 0.8886\n","Epoch 22/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1998 - accuracy: 0.9375 - val_loss: 0.3776 - val_accuracy: 0.8888\n","Epoch 23/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1973 - accuracy: 0.9382 - val_loss: 0.3776 - val_accuracy: 0.8890\n","Epoch 24/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1948 - accuracy: 0.9390 - val_loss: 0.3813 - val_accuracy: 0.8886\n","Epoch 25/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1924 - accuracy: 0.9395 - val_loss: 0.3812 - val_accuracy: 0.8889\n","Epoch 26/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1903 - accuracy: 0.9403 - val_loss: 0.3821 - val_accuracy: 0.8888\n","Epoch 27/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1881 - accuracy: 0.9408 - val_loss: 0.3849 - val_accuracy: 0.8883\n","Epoch 28/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1862 - accuracy: 0.9415 - val_loss: 0.3846 - val_accuracy: 0.8889\n","Epoch 29/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1843 - accuracy: 0.9419 - val_loss: 0.3851 - val_accuracy: 0.8888\n","Epoch 30/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1824 - accuracy: 0.9425 - val_loss: 0.3872 - val_accuracy: 0.8888\n","Epoch 31/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1806 - accuracy: 0.9431 - val_loss: 0.3902 - val_accuracy: 0.8881\n","Epoch 32/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1790 - accuracy: 0.9436 - val_loss: 0.3905 - val_accuracy: 0.8886\n","Epoch 33/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1774 - accuracy: 0.9440 - val_loss: 0.3918 - val_accuracy: 0.8886\n","Epoch 34/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1757 - accuracy: 0.9445 - val_loss: 0.3925 - val_accuracy: 0.8884\n","Epoch 35/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1743 - accuracy: 0.9449 - val_loss: 0.3951 - val_accuracy: 0.8881\n","Epoch 36/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1729 - accuracy: 0.9453 - val_loss: 0.3979 - val_accuracy: 0.8875\n","Epoch 37/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1715 - accuracy: 0.9457 - val_loss: 0.3995 - val_accuracy: 0.8878\n","Epoch 38/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1703 - accuracy: 0.9461 - val_loss: 0.4012 - val_accuracy: 0.8871\n","Epoch 39/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1689 - accuracy: 0.9465 - val_loss: 0.4009 - val_accuracy: 0.8876\n","Epoch 40/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1677 - accuracy: 0.9468 - val_loss: 0.4045 - val_accuracy: 0.8872\n","Epoch 41/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1666 - accuracy: 0.9472 - val_loss: 0.4052 - val_accuracy: 0.8871\n","Epoch 42/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1654 - accuracy: 0.9475 - val_loss: 0.4075 - val_accuracy: 0.8871\n","Epoch 43/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1643 - accuracy: 0.9478 - val_loss: 0.4084 - val_accuracy: 0.8868\n","Epoch 44/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1633 - accuracy: 0.9481 - val_loss: 0.4112 - val_accuracy: 0.8866\n","Epoch 45/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1622 - accuracy: 0.9484 - val_loss: 0.4129 - val_accuracy: 0.8861\n","Epoch 46/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1612 - accuracy: 0.9487 - val_loss: 0.4143 - val_accuracy: 0.8866\n","Epoch 47/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1602 - accuracy: 0.9489 - val_loss: 0.4135 - val_accuracy: 0.8866\n","Epoch 48/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1594 - accuracy: 0.9493 - val_loss: 0.4170 - val_accuracy: 0.8863\n","Epoch 49/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1584 - accuracy: 0.9496 - val_loss: 0.4187 - val_accuracy: 0.8866\n","Epoch 50/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1576 - accuracy: 0.9498 - val_loss: 0.4190 - val_accuracy: 0.8865\n","Epoch 51/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1569 - accuracy: 0.9500 - val_loss: 0.4215 - val_accuracy: 0.8857\n","Epoch 52/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1559 - accuracy: 0.9502 - val_loss: 0.4210 - val_accuracy: 0.8863\n","Epoch 53/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1551 - accuracy: 0.9505 - val_loss: 0.4249 - val_accuracy: 0.8850\n","Epoch 54/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1544 - accuracy: 0.9507 - val_loss: 0.4261 - val_accuracy: 0.8860\n","Epoch 55/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1537 - accuracy: 0.9509 - val_loss: 0.4246 - val_accuracy: 0.8857\n","Epoch 56/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1529 - accuracy: 0.9511 - val_loss: 0.4282 - val_accuracy: 0.8853\n","Epoch 57/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1522 - accuracy: 0.9513 - val_loss: 0.4278 - val_accuracy: 0.8859\n","Epoch 58/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1516 - accuracy: 0.9514 - val_loss: 0.4309 - val_accuracy: 0.8852\n","Epoch 59/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1508 - accuracy: 0.9517 - val_loss: 0.4326 - val_accuracy: 0.8849\n","Epoch 60/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1503 - accuracy: 0.9519 - val_loss: 0.4318 - val_accuracy: 0.8855\n","Epoch 61/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1496 - accuracy: 0.9521 - val_loss: 0.4340 - val_accuracy: 0.8851\n","Epoch 62/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1489 - accuracy: 0.9522 - val_loss: 0.4361 - val_accuracy: 0.8849\n","Epoch 63/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1484 - accuracy: 0.9524 - val_loss: 0.4393 - val_accuracy: 0.8843\n","Epoch 64/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1478 - accuracy: 0.9526 - val_loss: 0.4389 - val_accuracy: 0.8844\n","Epoch 65/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1472 - accuracy: 0.9528 - val_loss: 0.4428 - val_accuracy: 0.8840\n","Epoch 66/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1468 - accuracy: 0.9528 - val_loss: 0.4420 - val_accuracy: 0.8842\n","Epoch 67/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1462 - accuracy: 0.9530 - val_loss: 0.4408 - val_accuracy: 0.8842\n","Epoch 68/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1456 - accuracy: 0.9531 - val_loss: 0.4443 - val_accuracy: 0.8837\n","Epoch 69/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1451 - accuracy: 0.9532 - val_loss: 0.4430 - val_accuracy: 0.8844\n","Epoch 70/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1446 - accuracy: 0.9535 - val_loss: 0.4458 - val_accuracy: 0.8840\n","Epoch 71/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1441 - accuracy: 0.9536 - val_loss: 0.4471 - val_accuracy: 0.8842\n","Epoch 72/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1437 - accuracy: 0.9537 - val_loss: 0.4482 - val_accuracy: 0.8837\n","Epoch 73/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1430 - accuracy: 0.9539 - val_loss: 0.4494 - val_accuracy: 0.8838\n","Epoch 74/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1427 - accuracy: 0.9541 - val_loss: 0.4497 - val_accuracy: 0.8837\n","Epoch 75/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1423 - accuracy: 0.9541 - val_loss: 0.4516 - val_accuracy: 0.8834\n","Epoch 76/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1418 - accuracy: 0.9543 - val_loss: 0.4524 - val_accuracy: 0.8833\n","Epoch 77/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1415 - accuracy: 0.9543 - val_loss: 0.4544 - val_accuracy: 0.8832\n","Epoch 78/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1411 - accuracy: 0.9545 - val_loss: 0.4543 - val_accuracy: 0.8835\n","Epoch 79/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1406 - accuracy: 0.9546 - val_loss: 0.4566 - val_accuracy: 0.8831\n","Epoch 80/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1402 - accuracy: 0.9547 - val_loss: 0.4560 - val_accuracy: 0.8835\n","Epoch 81/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1396 - accuracy: 0.9549 - val_loss: 0.4571 - val_accuracy: 0.8832\n","Epoch 82/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1394 - accuracy: 0.9550 - val_loss: 0.4587 - val_accuracy: 0.8835\n","Epoch 83/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1389 - accuracy: 0.9550 - val_loss: 0.4577 - val_accuracy: 0.8834\n","Epoch 84/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1387 - accuracy: 0.9552 - val_loss: 0.4591 - val_accuracy: 0.8831\n","Epoch 85/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1382 - accuracy: 0.9553 - val_loss: 0.4598 - val_accuracy: 0.8829\n","Epoch 86/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1379 - accuracy: 0.9553 - val_loss: 0.4620 - val_accuracy: 0.8826\n","Epoch 87/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1376 - accuracy: 0.9554 - val_loss: 0.4637 - val_accuracy: 0.8827\n","Epoch 88/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1373 - accuracy: 0.9556 - val_loss: 0.4638 - val_accuracy: 0.8826\n","Epoch 89/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1368 - accuracy: 0.9557 - val_loss: 0.4633 - val_accuracy: 0.8833\n","Epoch 90/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1366 - accuracy: 0.9557 - val_loss: 0.4657 - val_accuracy: 0.8824\n","Epoch 91/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1363 - accuracy: 0.9558 - val_loss: 0.4678 - val_accuracy: 0.8825\n","Epoch 92/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1366 - accuracy: 0.9557 - val_loss: 0.4678 - val_accuracy: 0.8827\n","Epoch 93/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1356 - accuracy: 0.9561 - val_loss: 0.4696 - val_accuracy: 0.8826\n","Epoch 94/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1353 - accuracy: 0.9561 - val_loss: 0.4700 - val_accuracy: 0.8820\n","Epoch 95/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1350 - accuracy: 0.9562 - val_loss: 0.4710 - val_accuracy: 0.8823\n","Epoch 96/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1348 - accuracy: 0.9562 - val_loss: 0.4717 - val_accuracy: 0.8823\n","Epoch 97/100\n","1250/1250 [==============================] - 19s 15ms/step - loss: 0.1345 - accuracy: 0.9564 - val_loss: 0.4699 - val_accuracy: 0.8822\n","Epoch 98/100\n","1250/1250 [==============================] - 19s 16ms/step - loss: 0.1342 - accuracy: 0.9565 - val_loss: 0.4724 - val_accuracy: 0.8822\n","Epoch 99/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1339 - accuracy: 0.9564 - val_loss: 0.4735 - val_accuracy: 0.8819\n","Epoch 100/100\n","1250/1250 [==============================] - 20s 16ms/step - loss: 0.1337 - accuracy: 0.9565 - val_loss: 0.4737 - val_accuracy: 0.8824\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7feacc096850>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"rTg83acmQ_xE","executionInfo":{"status":"ok","timestamp":1627927507243,"user_tz":-330,"elapsed":431,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}}},"source":["encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)\n","\n","reverse_input_char_index=dict((i,char) for char,i in input_token_index.items())\n","reverse_target_char_index=dict((i,char) for char,i in target_token_index.items())\n","def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDX0b_2Oc6sA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627927734615,"user_tz":-330,"elapsed":76243,"user":{"displayName":"Avadhesh Chamola","photoUrl":"","userId":"04538323893662383879"}},"outputId":"0eb6639a-c2c1-4c9a-ddf4-1888e541ab57"},"source":["for seq_index in range (1000,1100):\n","  input_seq=encoder_input_data[seq_index:seq_index+1]\n","  decode_sentence=decode_sequence(input_seq)\n","  print('-')\n","  print('Input sentence:',input_texts[seq_index])\n","  print('target sentence:',target_texts[seq_index])\n","  print('decoded sentences',decode_sentence)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["-\n","Input sentence: I crashed.\n","target sentence: \tJe me suis écrasé.\n","\n","decoded sentences Je me suis fait tous les deux.\n","\n","-\n","Input sentence: I crashed.\n","target sentence: \tJe me suis écrasée.\n","\n","decoded sentences Je me suis fait tous les deux.\n","\n","-\n","Input sentence: I cringed.\n","target sentence: \tJ'eus un mouvement de recul.\n","\n","decoded sentences J'ai réparé les yeux.\n","\n","-\n","Input sentence: I cringed.\n","target sentence: \tJ'ai eu un mouvement de recul.\n","\n","decoded sentences J'ai réparé les yeux.\n","\n","-\n","Input sentence: I cringed.\n","target sentence: \tJe suis rentré en moi-même.\n","\n","decoded sentences J'ai réparé les yeux.\n","\n","-\n","Input sentence: I exhaled.\n","target sentence: \tJ’ai expiré.\n","\n","decoded sentences J'ai débarrassé.\n","\n","-\n","Input sentence: I frowned.\n","target sentence: \tJ'ai froncé les sourcils.\n","\n","decoded sentences J'ai froidé la question.\n","\n","-\n","Input sentence: I gave up.\n","target sentence: \tJ'ai abandonné.\n","\n","decoded sentences J'ai abandonné.\n","\n","-\n","Input sentence: I give in.\n","target sentence: \tJe donne ma langue au chat.\n","\n","decoded sentences J'ai consulté.\n","\n","-\n","Input sentence: I give up.\n","target sentence: \tJ'abandonne.\n","\n","decoded sentences J'ai gégé.\n","\n","-\n","Input sentence: I gloated.\n","target sentence: \tJ'ai jubilé.\n","\n","decoded sentences J'ai commencé.\n","\n","-\n","Input sentence: I got hot.\n","target sentence: \tJe me suis mis à avoir chaud.\n","\n","decoded sentences Je me suis mis à pleurer.\n","\n","-\n","Input sentence: I got hot.\n","target sentence: \tJe me suis mise à avoir chaud.\n","\n","decoded sentences Je me suis mis à pleurer.\n","\n","-\n","Input sentence: I grinned.\n","target sentence: \tJ'ai souri.\n","\n","decoded sentences J'ai pris un coup de soleil.\n","\n","-\n","Input sentence: I groaned.\n","target sentence: \tJ'ai gémi.\n","\n","decoded sentences J'ai gémis.\n","\n","-\n","Input sentence: I grunted.\n","target sentence: \tJ'ai grogné.\n","\n","decoded sentences J'ai été différent.\n","\n","-\n","Input sentence: I had fun.\n","target sentence: \tJe me suis amusé.\n","\n","decoded sentences Je me suis amusée.\n","\n","-\n","Input sentence: I had fun.\n","target sentence: \tJe me suis amusée.\n","\n","decoded sentences Je me suis amusée.\n","\n","-\n","Input sentence: I had fun.\n","target sentence: \tJe me suis marré.\n","\n","decoded sentences Je me suis amusée.\n","\n","-\n","Input sentence: I had fun.\n","target sentence: \tJe me suis marrée.\n","\n","decoded sentences Je me suis amusée.\n","\n","-\n","Input sentence: I hate it.\n","target sentence: \tJe déteste ça.\n","\n","decoded sentences Je déteste ça.\n","\n","-\n","Input sentence: I have it.\n","target sentence: \tJe l'ai.\n","\n","decoded sentences Je l'ai confusé.\n","\n","-\n","Input sentence: I hit Tom.\n","target sentence: \tJ'ai frappé Tom.\n","\n","decoded sentences J'ai frappé Tom.\n","\n","-\n","Input sentence: I hope so.\n","target sentence: \tJ'espère bien.\n","\n","decoded sentences J'espère enseignant.\n","\n","-\n","Input sentence: I hurried.\n","target sentence: \tJe me suis dépêché.\n","\n","decoded sentences Je me suis précipité.\n","\n","-\n","Input sentence: I hurried.\n","target sentence: \tJe me suis dépêchée.\n","\n","decoded sentences Je me suis précipité.\n","\n","-\n","Input sentence: I hurried.\n","target sentence: \tJe me suis précipité.\n","\n","decoded sentences Je me suis précipité.\n","\n","-\n","Input sentence: I hurried.\n","target sentence: \tJe me suis précipitée.\n","\n","decoded sentences Je me suis précipité.\n","\n","-\n","Input sentence: I inhaled.\n","target sentence: \tJ’ai inspiré.\n","\n","decoded sentences J'ai coupé.\n","\n","-\n","Input sentence: I knew it.\n","target sentence: \tJe le savais.\n","\n","decoded sentences Je le connais.\n","\n","-\n","Input sentence: I like it.\n","target sentence: \tÇa me plaît.\n","\n","decoded sentences J'aime les choses.\n","\n","-\n","Input sentence: I like it.\n","target sentence: \tJ'aime ça.\n","\n","decoded sentences J'aime les choses.\n","\n","-\n","Input sentence: I like it.\n","target sentence: \tJ'aime bien.\n","\n","decoded sentences J'aime les choses.\n","\n","-\n","Input sentence: I lost it.\n","target sentence: \tJe l’ai perdu.\n","\n","decoded sentences J'ai perdu.\n","\n","-\n","Input sentence: I love it!\n","target sentence: \tJ'adore ça !\n","\n","decoded sentences J'adore ça !\n","\n","-\n","Input sentence: I love it.\n","target sentence: \tJ'adore ça !\n","\n","decoded sentences J'adore ça.\n","\n","-\n","Input sentence: I mean it!\n","target sentence: \tJe suis sérieux !\n","\n","decoded sentences Je suis sérieux !\n","\n","-\n","Input sentence: I mean it.\n","target sentence: \tJe suis sérieux.\n","\n","decoded sentences Je suis sérieux.\n","\n","-\n","Input sentence: I must go.\n","target sentence: \tJe dois y aller.\n","\n","decoded sentences Il me faut y aller.\n","\n","-\n","Input sentence: I must go.\n","target sentence: \tIl faut que j'y aille.\n","\n","decoded sentences Il me faut y aller.\n","\n","-\n","Input sentence: I must go.\n","target sentence: \tIl me faut y aller.\n","\n","decoded sentences Il me faut y aller.\n","\n","-\n","Input sentence: I must go.\n","target sentence: \tIl me faut partir.\n","\n","decoded sentences Il me faut y aller.\n","\n","-\n","Input sentence: I must go.\n","target sentence: \tIl me faut m'en aller.\n","\n","decoded sentences Il me faut y aller.\n","\n","-\n","Input sentence: I must go.\n","target sentence: \tJe dois partir.\n","\n","decoded sentences Il me faut y aller.\n","\n","-\n","Input sentence: I must go.\n","target sentence: \tJe dois m'en aller.\n","\n","decoded sentences Il me faut y aller.\n","\n","-\n","Input sentence: I must go.\n","target sentence: \tIl faut que je m'en aille.\n","\n","decoded sentences Il me faut y aller.\n","\n","-\n","Input sentence: I need it.\n","target sentence: \tJ'en ai besoin.\n","\n","decoded sentences J'ai besoin de ça.\n","\n","-\n","Input sentence: I need it.\n","target sentence: \tIl me le faut.\n","\n","decoded sentences J'ai besoin de ça.\n","\n","-\n","Input sentence: I noticed.\n","target sentence: \tJ'ai remarqué.\n","\n","decoded sentences J'ai remarqué.\n","\n","-\n","Input sentence: I prepaid.\n","target sentence: \tJ'ai payé d'avance.\n","\n","decoded sentences J'ai payé de la main.\n","\n","-\n","Input sentence: I promise.\n","target sentence: \tJe le promets.\n","\n","decoded sentences Je promets.\n","\n","-\n","Input sentence: I promise.\n","target sentence: \tPromis.\n","\n","decoded sentences Je promets.\n","\n","-\n","Input sentence: I relaxed.\n","target sentence: \tJe me suis détendu.\n","\n","decoded sentences Je me suis détendue.\n","\n","-\n","Input sentence: I relaxed.\n","target sentence: \tJe me suis détendue.\n","\n","decoded sentences Je me suis détendue.\n","\n","-\n","Input sentence: I retired.\n","target sentence: \tJ'ai pris ma retraite.\n","\n","decoded sentences J'ai pris du poids.\n","\n","-\n","Input sentence: I retired.\n","target sentence: \tJe suis parti à la retraite.\n","\n","decoded sentences J'ai pris du poids.\n","\n","-\n","Input sentence: I retired.\n","target sentence: \tJe suis partie à la retraite.\n","\n","decoded sentences J'ai pris du poids.\n","\n","-\n","Input sentence: I said no.\n","target sentence: \tJ'ai dit non.\n","\n","decoded sentences J'ai dit non.\n","\n","-\n","Input sentence: I said so.\n","target sentence: \tJe l'ai dit.\n","\n","decoded sentences J'ai dit de boire.\n","\n","-\n","Input sentence: I saw Tom.\n","target sentence: \tJ'ai vu Tom.\n","\n","decoded sentences J'ai vu Tom.\n","\n","-\n","Input sentence: I saw Tom.\n","target sentence: \tJe voyais Tom.\n","\n","decoded sentences J'ai vu Tom.\n","\n","-\n","Input sentence: I saw him.\n","target sentence: \tJe l'ai vu.\n","\n","decoded sentences Je l'ai vu.\n","\n","-\n","Input sentence: I saw him.\n","target sentence: \tJe l’ai vu.\n","\n","decoded sentences Je l'ai vu.\n","\n","-\n","Input sentence: I saw him.\n","target sentence: \tJe le vis.\n","\n","decoded sentences Je l'ai vu.\n","\n","-\n","Input sentence: I saw one.\n","target sentence: \tJ'en ai vu une.\n","\n","decoded sentences J'ai vu Tom.\n","\n","-\n","Input sentence: I saw one.\n","target sentence: \tJ'en ai vu un.\n","\n","decoded sentences J'ai vu Tom.\n","\n","-\n","Input sentence: I saw you.\n","target sentence: \tJe vous vis.\n","\n","decoded sentences Je vous ai vues.\n","\n","-\n","Input sentence: I saw you.\n","target sentence: \tJe te vis.\n","\n","decoded sentences Je vous ai vues.\n","\n","-\n","Input sentence: I saw you.\n","target sentence: \tJe t'ai vue.\n","\n","decoded sentences Je vous ai vues.\n","\n","-\n","Input sentence: I saw you.\n","target sentence: \tJe t'ai vu.\n","\n","decoded sentences Je vous ai vues.\n","\n","-\n","Input sentence: I saw you.\n","target sentence: \tJe vous ai vues.\n","\n","decoded sentences Je vous ai vues.\n","\n","-\n","Input sentence: I saw you.\n","target sentence: \tJe vous ai vus.\n","\n","decoded sentences Je vous ai vues.\n","\n","-\n","Input sentence: I saw you.\n","target sentence: \tJe vous ai vue.\n","\n","decoded sentences Je vous ai vues.\n","\n","-\n","Input sentence: I saw you.\n","target sentence: \tJe vous ai vu.\n","\n","decoded sentences Je vous ai vues.\n","\n","-\n","Input sentence: I see Tom.\n","target sentence: \tJe vois Tom.\n","\n","decoded sentences Je vois Tom.\n","\n","-\n","Input sentence: I see you.\n","target sentence: \tJe te vois.\n","\n","decoded sentences Je vois voir ça.\n","\n","-\n","Input sentence: I shouted.\n","target sentence: \tJ'ai crié.\n","\n","decoded sentences Je me suis blond.\n","\n","-\n","Input sentence: I tripped.\n","target sentence: \tJ'ai trébuché.\n","\n","decoded sentences J'ai allumé.\n","\n","-\n","Input sentence: I tripped.\n","target sentence: \tJ'ai plané.\n","\n","decoded sentences J'ai allumé.\n","\n","-\n","Input sentence: I want it.\n","target sentence: \tJe le veux.\n","\n","decoded sentences J'en veux une bière.\n","\n","-\n","Input sentence: I was new.\n","target sentence: \tJ'étais nouveau.\n","\n","decoded sentences J'étais malade.\n","\n","-\n","Input sentence: I was new.\n","target sentence: \tJ'étais nouvelle.\n","\n","decoded sentences J'étais malade.\n","\n","-\n","Input sentence: I will go.\n","target sentence: \tJ'irai.\n","\n","decoded sentences J'irai.\n","\n","-\n","Input sentence: I woke up.\n","target sentence: \tJe me suis réveillé.\n","\n","decoded sentences Je me suis remié.\n","\n","-\n","Input sentence: I woke up.\n","target sentence: \tJe me suis éveillé.\n","\n","decoded sentences Je me suis remié.\n","\n","-\n","Input sentence: I'd agree.\n","target sentence: \tJe serais d'accord.\n","\n","decoded sentences Je partagera.\n","\n","-\n","Input sentence: I'd leave.\n","target sentence: \tJe partirais.\n","\n","decoded sentences J'aimerais manger.\n","\n","-\n","Input sentence: I'll call.\n","target sentence: \tJ'appellerai.\n","\n","decoded sentences Je le perdrai.\n","\n","-\n","Input sentence: I'll come.\n","target sentence: \tJe viendrai.\n","\n","decoded sentences Je viendrai.\n","\n","-\n","Input sentence: I'll cook.\n","target sentence: \tJe cuisinerai.\n","\n","decoded sentences Je cuisinerai.\n","\n","-\n","Input sentence: I'll help.\n","target sentence: \tJ'aiderai.\n","\n","decoded sentences J'ai recourre.\n","\n","-\n","Input sentence: I'll live.\n","target sentence: \tJe vivrai.\n","\n","decoded sentences Je viserai.\n","\n","-\n","Input sentence: I'll obey.\n","target sentence: \tJ'obéirai.\n","\n","decoded sentences J'achèterai.\n","\n","-\n","Input sentence: I'll pack.\n","target sentence: \tJe ferai mon sac.\n","\n","decoded sentences Je plierai mon chapeau.\n","\n","-\n","Input sentence: I'll pack.\n","target sentence: \tJe ferai ma valise.\n","\n","decoded sentences Je plierai mon chapeau.\n","\n","-\n","Input sentence: I'll pack.\n","target sentence: \tJe plierai mes gaules.\n","\n","decoded sentences Je plierai mon chapeau.\n","\n","-\n","Input sentence: I'll pass.\n","target sentence: \tJe passerai.\n","\n","decoded sentences Je passerai.\n","\n","-\n","Input sentence: I'll quit.\n","target sentence: \tJ'abandonnerai.\n","\n","decoded sentences J'ai rien dit.\n","\n","-\n","Input sentence: I'll sing.\n","target sentence: \tJe chanterai.\n","\n","decoded sentences Je tirerai.\n","\n","-\n","Input sentence: I'll stay.\n","target sentence: \tJe vais rester.\n","\n","decoded sentences Je vais prendre mon manteau.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L-cgLMyEfWrX"},"source":[""],"execution_count":null,"outputs":[]}]}